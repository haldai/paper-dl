#!/usr/bin/env bash

black="\033[30m"
red="\033[31m"
green="\033[32m"
yellow="\033[33m"
blue="\033[34m"
purple="\033[35m"
cyan="\033[36m"
gray="\033[37m"
nc="\033[0m"

function create() {
    case "$1" in
    "d")
        if [ ! -d "$2" ]; then
            mkdir "$2"
        fi
        ;;
    "f")
        if [ -f "$2" ]; then
            rm "$2"
        else
            touch "$2"
        fi
        ;;
    esac
}

function delete() {
    case "$1" in
    "d")
        if [ -d "$2" ]; then
            rm -r "$2"
        fi
        ;;
    "f")
        if [ -f "$2" ]; then
            rm "$2"
        fi
        ;;
    esac
}

if [ $# -lt 2 ]; then
    echo -e "${red}Error: two args at least!${nc}" && exit 1
fi

if [ "$1" != pmlr ] && [ "$1" != nips ]; then
    echo -e "${red}Error: illegal 1st arg!${nc}" && exit 1
fi

create d "$HOME/.cache"
create d "$HOME/.cache/paper-dl"
create d "$HOME/.cache/paper-dl/$1"
html_cache="$HOME/.cache/paper-dl/$1"

case $1 in
pmlr)
    host=http://proceedings.mlr.press/
    wget -t 0 -q -O $html_cache/index.html $host
    proceeding_name=$(cat $html_cache/index.html | sed -n "s/.*$2.*\/a.\(.*\)/\1/p")
    proceeding_url=$(cat $html_cache/index.html | sed -n "s/.*href=\"\(.*\)\".*$2.*/\1/p")
    ;;
nips)
    host=http://papers.nips.cc
    wget -t 0 -q -O $html_cache/index.html $host
    proceeding_name=$(cat $html_cache/index.html | sed -n "s/.*\".\(.*Systems $2.*\).\/a.*/\1/p")
    proceeding_url=$(cat $html_cache/index.html | sed -n "s/.*href=\"\(.*\)\".*Systems $2.*/\1/p")
    ;;
esac

proceeding_name=$(echo $proceeding_name | sed -e 's/^[ ]*//g' | sed -e 's/[ ]*$//g')

if [ -z "$proceeding_name" ]; then
    echo -e "${red}Error: illegal 2nd arg!${nc}" && exit 1
fi

delete f $html_cache/index.html

if [ ! -f $html_cache/$1-$2.html ]; then
    echo -e "${yellow}It's the first time to download $proceeding_name. Please be patient while caching the paper list:${nc}"
    wget -t 0 -q --show-progress -O $html_cache/$1-$2.html $host$proceeding_url
fi

i=0 && j=0 && k=0 && url_line=0 && author_line=0
while read -r line; do
    case $1 in
    'pmlr')
        if [[ "$line" =~ '"title"' ]]; then
            if [ $# == 2 ]; then
                title_array[$i]=$(echo $line | sed -n 's/.*title".\(.*\).\/p.*/\1/p') && ((i++))
            else
                keywords_find=1
                for arg in $@; do
                    arg=${arg,,}
                    if [ "$arg" != "$1" ] && [ "$arg" != "$2" ] && [[ ! "$line" =~ "$arg" ]] && [[ ! "$line" =~ "${arg^}" ]] && [[ ! "$line" =~ "${arg,}" ]] && [[ ! "$line" =~ "${arg^^}" ]]; then
                        keywords_find=0
                    fi
                done
                if [ "$keywords_find" == 1 ]; then
                    title_array[$i]=$(echo $line | sed -n 's/.*title".\(.*\).\/p.*/\1/p') && author_line=1 && url_line=1 && ((i++))
                fi
            fi
        fi

        if [ $# == 2 ] || [ $author_line == 1 ]; then
            if [[ "$line" =~ '</span>' ]] && [ "$flag" == 1 ]; then
                flag=0
                author_array[$k]="${author:0:-1}" && ((k++))
                author_line=0
            fi
            if [ "$flag" == 1 ]; then
                line=$(echo "$line" | sed -e 's/^[ ]*//g' | sed -e 's/[ ]*$//g')
                if [ -n "$line" ]; then
                    author="$author$line "
                fi
            fi
            if [[ "$line" =~ '<span class="authors">' ]]; then
                flag=1
                author=""
            fi
        fi

        if [[ "$line" =~ 'Download PDF' ]]; then
            if [ $# == 2 ]; then
                url_array[$j]="$line" && ((j++))
            else
                if [ "$url_line" == 1 ]; then
                    url_array[$j]="$line" && url_line=0 && ((j++))
                fi
            fi
        fi
        ;;
    'nips')
        if [[ "$line" =~ '<li><a href="/paper/' ]]; then
            if [ ${#@} == 2 ]; then
                url_array[$i]=$(echo $line | perl -pe 's|(">.*?)</a>.*|\1|' | sed -n 's/.*href="\(.*\)".*/\1/p')
                title_array[$i]=$(echo $line | perl -pe 's|(">.*?)</a>.*|\1|' | sed -n 's/.*">\(.*\)/\1/p')
                line_array=($(echo $line | tr ' ' '?' | tr ',' ' '))
                author=""
                for value in "${line_array[@]}"; do
                    author="$author$(echo $value | sed -n 's/.*"author">\(.*\)<\/a>.*/\1/p' | tr '?' ' '), "
                done
                author_array[$i]="${author:0:-2}"
                ((i++))
            else
                keywords_find=1
                for arg in $@; do
                    arg=${arg,,}
                    if [ "$arg" != "$1" ] && [ "$arg" != "$2" ] && [[ ! "$line" =~ "$arg" ]] && [[ ! "$line" =~ "${arg^}" ]] && [[ ! "$line" =~ "${arg,}" ]] && [[ ! "$line" =~ "${arg^^}" ]]; then
                        keywords_find=0
                    fi
                done
                if [ "$keywords_find" == 1 ]; then
                    url_array[$i]=$(echo $line | perl -pe 's|(">.*?)</a>.*|\1|' | sed -n 's/.*href="\(.*\)".*/\1/p')
                    title_array[$i]=$(echo $line | perl -pe 's|(">.*?)</a>.*|\1|' | sed -n 's/.*">\(.*\)/\1/p')
                    line_array=($(echo $line | tr ' ' '?' | tr ',' ' '))
                    author=""
                    for value in "${line_array[@]}"; do
                        author="$author$(echo $value | sed -n 's/.*"author">\(.*\)<\/a>.*/\1/p' | tr '?' ' '), "
                    done
                    author_array[$i]="${author:0:-2}"
                    ((i++))
                fi
            fi
        fi
        ;;
    esac
done <$html_cache/$1-$2.html

query_num=$i && j=$i

if [ -d "$proceeding_name" ]; then
    downloaded_paper_list=$(ls "$proceeding_name")
fi

downloaded_num=0
if [ "$i" -gt 0 ]; then
    while [ "$i" -gt 0 ]; do
        echo -e "${purple}$i${nc} \c"
        ((i--))
        case $1 in
        'pmlr')
            title=${title_array[$i]}
            ;;
        'nips')
            title=${url_array[$i]}
            title=(${title//\// })
            title=${title[-1]}
            title=${title:0:-4}
            ;;
        esac
        if [[ "$downloaded_paper_list" =~ "$title" ]]; then
            printf "${gray}%s ${yellow}(Downloaded)${nc}\n" "${title_array[$i]}"
            select_array[$i]=0
            ((j--)) && ((downloaded_num++))
        else
            select_array[$i]=1
            echo "${title_array[$i]}"
        fi
        echo -e "${cyan}\033[3m    ${author_array[$i]}\033[23m${nc}"
    done
    if [ "$j" == 0 ]; then
        echo -e "${red}==> All papers have been downloaded!${nc}" && exit 1
    else
        if [ "$downloaded_num" == 0 ]; then
            echo -e "${yellow}==> Papers to download (eg: 1 2 3, 1-3 or ^3), default all ($query_num)${nc}"
        else
            echo -e "${yellow}==> Papers to download (eg: 1 2 3, 1-3 or ^3), default all ($query_num-$downloaded_num=$j)${nc}"
        fi
        read -p $'\033[33m==> \033[0m' input
    fi
else
    echo -e "${red}Warning: no papers meet the query conditions!${nc}" && exit 1
fi

if [ -n "${input// /}" ]; then
    for k in "${!select_array[@]}"; do
        select_array[$k]=0
    done

    input=($input)

    for value in ${input[@]}; do
        if [ "$(echo "$value" | awk '{print($0~/^[1-9][0-9]*-[1-9][0-9]*$/)}')" == 1 ]; then
            i=$(echo "$value" | cut -d '-' -f 1) && j=$(echo "$value" | cut -d '-' -f 2)
            while [ "$i" -le "$j" ] && [ "$i" -le "$query_num" ]; do
                select_array[$(($i - 1))]=1 && ((i++))
            done
        elif [ "$(echo "$value" | awk '{print($0~/^[1-9][0-9]*$/)}')" == 1 ]; then
            if [ "$value" -le "$query_num" ]; then
                select_array[$(($value - 1))]=1
            fi
        fi
    done

    for value in ${input[@]}; do
        if [ "$(echo "$value" | awk '{print($0~/^[\^][0-9]*-[1-9][0-9]*$/)}')" == 1 ]; then
            value=${value:1}
            i=$(echo "$value" | cut -d '-' -f 1) && j=$(echo "$value" | cut -d '-' -f 2)
            k=0
            while [ "$k" -lt "$query_num" ]; do
                if [ "$k" -lt "$i" ] || [ "$k" -ge "$j" ]; then
                    select_array[$k]=1
                fi
                ((k++))
            done
        elif [ "$(echo "$value" | awk '{print($0~/^[\^][1-9][0-9]*$/)}')" == 1 ]; then
            value=${value:1}
            k=0
            while [ "$k" -lt "$query_num" ]; do
                if [ "$k" != "$(($value - 1))" ]; then
                    select_array[$k]=1
                fi
                ((k++))
            done
        fi
    done

    for value in ${input[@]}; do
        if [ "$(echo "$value" | awk '{print($0~/^[\^][0-9]*-[1-9][0-9]*$/)}')" == 1 ]; then
            value=${value:1}
            i=$(echo "$value" | cut -d '-' -f 1)
            j=$(echo "$value" | cut -d '-' -f 2)
            while [ "$i" -le "$j" ] && [ "$i" -le "$query_num" ]; do
                select_array[$(($i - 1))]=0 && ((i++))
            done
        elif [ "$(echo "$value" | awk '{print($0~/^[\^][1-9][0-9]*$/)}')" == 1 ]; then
            value=${value:1}
            if [ "$value" -le "$query_num" ]; then
                select_array[$(($value - 1))]=0
            fi
        fi
    done
fi

total=0
for value in ${select_array[@]}; do
    if [ "$value" == 1 ]; then
        ((total++))
    fi
done

if [ "$total" -gt 0 ]; then
    create d "$proceeding_name" && cd "$proceeding_name"
    i=0 && j=0
    while [ "$i" -lt "$query_num" ]; do
        if [ "${select_array[$i]}" == 1 ]; then
            title=${title_array[$i]}

            ((j++))
            awk 'BEGIN{printf "\033[35m\n%d/%d (%.2f%)\033[0m", '$j', '$total', (100 * '$j'/'$total')}'
            echo -e " $title"

            case $1 in
            'pmlr')
                title=${title//\//?}
                create d "$title" && cd "$title"

                pdf_url=$(echo ${url_array[$i]} | sed -n 's/.*href="\(.*[1-9][1-9][a-z].pdf\)" target.*/\1/p')
                pdf_url_array=(${pdf_url//\// })
                pdf_name=${pdf_url_array[-1]}

                echo -e "${yellow}Download paper: ${nc}"
                wget -t 0 -q --show-progress -O "$pdf_name" $pdf_url

                if [[ "${url_array[$i]}" =~ 'Supplementary PDF' ]]; then
                    supp_url=$(echo "${url_array[$i]}" | sed -n 's/.*Download PDF.*href="\(.*-supp.pdf\)" target.*/\1/p')
                    supp_url_array=(${supp_url//\// })
                    supp_name=${supp_url_array[-1]}

                    echo -e "${yellow}Download supplementary: ${nc}"
                    wget -t 0 -q --show-progress -O "$supp_name" $supp_url

                    gs -dBATCH -dNOPAUSE -q -sDEVICE=pdfwrite -sOutputFile="${pdf_name:0:-4}-merge.pdf" "$pdf_name" "$supp_name"
                fi
                cd ..
                ;;
            'nips')
                wget -t 0 -q -O "$html_cache/paper.html" "$host${url_array[$i]}"

                pdf_url=$(cat "$html_cache/paper.html" | sed -n 's/.*href="\(.*\)".*PDF.*/\1/p')
                pdf_url_array=(${pdf_url//\// })
                pdf_name=${pdf_url_array[-1]}

                title=${pdf_name:0:-4}
                create d "$title" && cd "$title" # 只能用截取pdf_name创建文件夹 正常标题有的用了latex符号 都是非法字符

                echo -e "${yellow}Download paper: ${nc}"
                wget -t 0 -q --show-progress -O "$pdf_name" $host$pdf_url

                bib_url=$(cat "$html_cache/paper.html" | sed -n 's/.*href="\(.*\)".*BibTeX.*/\1/p')
                echo -e "${yellow}Download bib: ${nc}"
                wget -t 0 -q --show-progress -P . $host$bib_url

                supplemental_url=$(cat "$html_cache/paper.html" | sed -n 's/.*href="\(.*\)".*Supplemental.*/\1/p')
                echo -e "${yellow}Download supplemental: ${nc}"
                wget -t 0 -q --show-progress -P . $host$supplemental_url

                supplemental=$(find . -maxdepth 1 -regextype posix-extended -iregex '.*\.(zip)')
                if [ -n "$supplemental" ]; then
                    create d supp
                    unzip -q "$supplemental" -d supp
                    merge_command="gs -dBATCH -dNOPAUSE -q -sDEVICE=pdfwrite -sOutputFile='${pdf_name:0:-4}-merge.pdf' '$pdf_name'"
                    for line in $(find supp -maxdepth 1 -regextype posix-extended -iregex '.*\.(pdf)' | tr ' ' '\?'); do
                        merge_command="$merge_command '$line'"
                    done
                    merge_command=$(echo "$merge_command" | tr '\?' ' ')
                    eval "$merge_command"
                    delete d supp
                else
                    echo "no supplemental"
                fi

                review_url=$(cat "$html_cache/paper.html" | sed -n 's/.*href="\/\/\(.*\)".*Reviews.*/\1/p')
                echo -e "${yellow}Download review: ${nc}"
                wget -t 0 -q --show-progress -P . $review_url

                delete f "$html_cache/paper.html"
                cd ..
                ;;
            esac
        fi
        ((i++))
    done
else
    echo -e "${red}Warning: there is nothing to do!${nc}"
fi
