#!/usr/bin/env bash

black="\033[30m"
red="\033[31m"
green="\033[32m"
yellow="\033[33m"
blue="\033[34m"
purple="\033[35m"
skyblue="\033[36m"
nc="\033[0m"

# create d html || create f a.txt
function create() {
    case "$1" in
    "d")
        if [ ! -d "$2" ]; then
            mkdir "$2"
        fi
        ;;
    "f")
        if [ -f "$2" ]; then
            rm "$2"
        else
            touch "$2"
        fi
        ;;
    esac
}

# delete d html || delete f a.txt
function delete() {
    case "$1" in
    "d")
        if [ -d "$2" ]; then
            rm -r "$2"
        fi
        ;;
    "f")
        if [ -f "$2" ]; then
            rm "$2"
        fi
        ;;
    esac
}

# d_wget http://proceedings.mlr.press/ html/jmlr root.html [q]
function d_wget() {
    if [ "$3" == "q" ]; then # slient mode
        wget -t0 -q "$1" -O "$2"
    else
        wget -t0 -c -nv --show-progress "$1" -O "$2"
    fi
}

if [ $# -lt 2 ]; then
    echo -e "${red}Error: two parameters at least!${nc}" && exit 1
fi

html_cache="$HOME/.cache/paper-dl"
create d $html_cache
delete "$html_cache/host.html"

case $1 in
'pmlr')
    host='http://proceedings.mlr.press/'
    d_wget $host "$html_cache/host.html" q
    folder=$(cat "$html_cache/host.html" | sed -n "s/.*$2.*\/a. \(.*\)/\1/p")
    proceeding_url=$(cat "$html_cache/host.html" | sed -n "s/.*href=\"\(.*\)\".*$2.*/\1/p")
    ;;
'nips')
    host='http://papers.nips.cc'
    d_wget $host "$html_cache/host.html" q
    folder=$(cat "$html_cache/host.html" | sed -n "s/.*\".\(.*NIPS $2.*\).\/a.*/\1/p")
    proceeding_url=$(cat "$html_cache/host.html" | sed -n "s/.*href=\"\(.*\)\".*NIPS $2.*/\1/p")
    ;;
esac

delete f "$html_cache/host.html"

if [ -z "$folder" ]; then
    echo -e "${red}Error: illegal 2nd parameter!${nc}" && exit 1
fi

if [ ! -f "$html_cache/$1-$2.html" ]; then
    d_wget "$host$proceeding_url" "$html_cache/$1-$2.html" q
fi

i=0 && j=0 && url_line=0
while read -r line; do
    case $1 in
    'pmlr')
        if [[ "$line" =~ '"title"' ]]; then
            if [ $# == 2 ]; then
                title_array[$i]=$(echo $line | sed -n 's/.*title".\(.*\).\/p.*/\1/p') && ((i++))
            else
                keywords_find=1
                for arg in $@; do
                    arg=${arg,,}
                    if [ "$arg" != "$1" ] && [ "$arg" != "$2" ] && [[ ! "$line" =~ "$arg" ]] && [[ ! "$line" =~ "${arg^}" ]] && [[ ! "$line" =~ "${arg,}" ]] && [[ ! "$line" =~ "${arg^^}" ]]; then
                        keywords_find=0
                    fi
                done
                if [ "$keywords_find" == 1 ]; then
                    title_array[$i]=$(echo $line | sed -n 's/.*title".\(.*\).\/p.*/\1/p') && url_line=1 && ((i++))
                fi
            fi
        fi
        if [[ "$line" =~ 'Download PDF' ]]; then
            if [ $# == 2 ]; then
                url_array[$j]="$line" && ((j++))
            else
                if [ "$url_line" == 1 ]; then
                    url_array[$j]="$line" && url_line=0 && ((j++))
                fi
            fi
        fi
        ;;
    'nips')
        if [[ "$line" =~ '<li><a href="/paper/' ]]; then
            if [ ${#@} == 2 ]; then
                url_array[$i]=$(echo $line | perl -pe 's|(\">.*?)</a>.*|\1|' | sed -n 's/.*href="\(.*\)".*/\1/p')
                title_array[$i]=$(echo $line | perl -pe 's|(\">.*?)</a>.*|\1|' | sed -n 's/.*">\(.*\)/\1/p')
                ((i++))
            else
                keywords_find=1
                for arg in $@; do
                    arg=${arg,,}
                    if [ "$arg" != "$1" ] && [ "$arg" != "$2" ] && [[ ! "$line" =~ "$arg" ]] && [[ ! "$line" =~ "${arg^}" ]] && [[ ! "$line" =~ "${arg,}" ]] && [[ ! "$line" =~ "${arg^^}" ]]; then
                        keywords_find=0
                    fi
                done
                if [ "$keywords_find" == 1 ]; then
                    url_array[$i]=$(echo $line | perl -pe 's|(\">.*?)</a>.*|\1|' | sed -n 's/.*href="\(.*\)".*/\1/p')
                    title_array[$i]="$(echo $line | perl -pe 's|(\">.*?)</a>.*|\1|' | sed -n 's/.*">\(.*\)/\1/p')"
                    ((i++))
                fi
            fi
        fi
        ;;
    esac
done <"$html_cache/$1-$2.html"

len=$i

if [ "$i" -gt 0 ]; then
    while [ "$i" -gt 0 ]; do
        echo -e "${purple}$i${nc} \c"
        echo "${title_array[$(($i - 1))]}"
        ((i--)) && select_array[$i]=0
    done
    echo -e "${yellow}==> Papers to download (eg: 1 2 3, 1-3 or ^3), default all ($len)${nc}"
    read -p $'\033[33m==> \033[0m' input
else
    echo -e "${red}Warning: no papers meet the query conditions!${nc}" && exit 1
fi

if [ -z "${input// /}" ]; then
    for i in "${!select_array[@]}"; do
        select_array[i]=1
    done
else
    input=($input)
    for value in ${input[@]}; do
        if [ "$(echo "$value" | awk '{print($0~/^[1-9][0-9]*-[1-9][0-9]*$/)}')" == 1 ]; then
            i=$(echo "$value" | cut -d '-' -f 1) && j=$(echo "$value" | cut -d '-' -f 2)
            while [ "$i" -le "$j" ] && [ "$i" -le "$len" ]; do
                select_array[$(($i - 1))]=1 && ((i++))
            done
        elif [ "$(echo "$value" | awk '{print($0~/^[1-9][0-9]*$/)}')" == 1 ]; then
            if [ "$value" -le "$len" ]; then
                select_array[$(($value - 1))]=1
            fi
        fi
    done

    for value in ${input[@]}; do
        if [ "$(echo "$value" | awk '{print($0~/^[\^][0-9]*-[1-9][0-9]*$/)}')" == 1 ]; then
            value=${value:1}
            i=$(echo "$value" | cut -d '-' -f 1) && j=$(echo "$value" | cut -d '-' -f 2)
            k=0
            while [ "$k" -lt "$len" ]; do
                if [ "$k" -lt "$i" ] || [ "$k" -ge "$j" ]; then
                    select_array[$k]=1
                fi
                ((k++))
            done
        elif [ "$(echo "$value" | awk '{print($0~/^[\^][1-9][0-9]*$/)}')" == 1 ]; then
            value=${value:1}
            k=0
            while [ "$k" -lt "$len" ]; do
                if [ "$k" != "$(($value - 1))" ]; then
                    select_array[$k]=1
                fi
                ((k++))
            done
        fi
    done

    for value in ${input[@]}; do
        if [ "$(echo "$value" | awk '{print($0~/^[\^][0-9]*-[1-9][0-9]*$/)}')" == 1 ]; then
            value=${value:1}
            i=$(echo "$value" | cut -d '-' -f 1)
            j=$(echo "$value" | cut -d '-' -f 2)
            while [ "$i" -le "$j" ] && [ "$i" -le "$len" ]; do
                select_array[$(($i - 1))]=0 && ((i++))
            done
        elif [ "$(echo "$value" | awk '{print($0~/^[\^][1-9][0-9]*$/)}')" == 1 ]; then
            value=${value:1}
            if [ "$value" -le "$len" ]; then
                select_array[$(($value - 1))]=0
            fi
        fi
    done
fi

total=0
for value in ${select_array[@]}; do
    if [ "$value" == 1 ]; then
        ((total++))
    fi
done

if [ "$total" -gt 0 ]; then
    create d "$folder"

    i=0 && j=0
    while [ "$i" -lt "$len" ]; do
        if [ "${select_array[$i]}" == 1 ]; then
            title=${title_array[$i]}
            create d "$folder/$title"

            ((j++))
            awk 'BEGIN{printf "\033[35m\n%d/%d (%.2f%)\033[0m", '$j', '$total', (100 * '$j'/'$total')}'
            echo -e " $title"

            case $1 in
            'pmlr')
                pdf_url=$(echo ${url_array[$i]} | sed -n 's/.*href="\(.*[1-9][1-9][a-z].pdf\)" target.*/\1/p')
                pdf_url_array=(${pdf_url//\// })
                pdf_name=${pdf_url_array[-1]}
                if [ -f "$folder/$title/$pdf_name" ]; then
                    echo -e "${yellow}Paper already exists!${nc}"
                else
                    echo -e "${yellow}Download paper: ${nc}"
                    d_wget "$pdf_url" "$folder/$title/$pdf_name"
                fi

                if [[ "${url_array[$i]}" =~ 'Supplementary PDF' ]]; then
                    supp_url=$(echo "${url_array[$i]}" | sed -n 's/.*Download PDF.*href="\(.*-supp.pdf\)" target.*/\1/p')
                    supp_url_array=(${supp_url//\// })
                    supp_name=${supp_url_array[-1]}
                    if [ -f "$folder/$title/$supp_name" ]; then
                        echo -e "${yellow}Supplementary already exists!${nc}"
                    else
                        echo -e "${yellow}Download supplementary: ${nc}"
                        d_wget "$supp_url" "$folder/$title/$supp_name"
                    fi

                    # 合并
                    echo -e "${yellow}Merge:${nc} ${pdf_name:0:-4}-merge.pdf"
                    gs -dBATCH -dNOPAUSE -q -sDEVICE=pdfwrite -sOutputFile="$folder/$title/${pdf_name:0:-4}-merge.pdf" "$folder/$title/$pdf_name" "$folder/$title/$supp_name"
                fi
                ;;
            'nips')
                d_wget "$host${url_array[$i]}" "$html_cache/paper.html" q

                pdf_url=$(cat "$html_cache/paper.html" | sed -n 's/.*href="\(.*\)".*PDF.*/\1/p')
                pdf_url_array=(${pdf_url//\// })
                pdf_name=${pdf_url_array[-1]}
                if [ -f "$folder/$title/$pdf_name" ]; then
                    echo -e "${yellow}Paper already exists!${nc}"
                else
                    echo -e "${yellow}Download paper: ${nc}"
                    d_wget "$host$pdf_url" "$folder/$title/$pdf_name"
                fi

                bib_url=$(cat "$html_cache/paper.html" | sed -n 's/.*href="\(.*\)".*BibTeX.*/\1/p')
                if [ -f "$folder/$title/${pdf_name:0:-4}.bib" ]; then
                    echo -e "${yellow}Bib already exists!${nc}"
                else
                    echo -e "${yellow}Download bib: ${nc}"
                    d_wget "$host$bib_url" "$folder/$title/${pdf_name:0:-4}.bib"
                fi

                supplemental_url=$(cat "$html_cache/paper.html" | sed -n 's/.*href="\(.*\)".*Supplemental.*/\1/p')
                if [ -f "$folder/$title/${pdf_name:0:-4}.zip" ]; then
                    echo -e "${yellow}Supplemental already exists!${nc}"
                else
                    echo -e "${yellow}Download supplemental: ${nc}"
                    d_wget "$host$supplemental_url" "$folder/$title/${pdf_name:0:-4}.zip"
                fi

                review_url=$(cat "$html_cache/paper.html" | sed -n 's/.*href="\/\/\(.*\)".*Reviews.*/\1/p')
                if [ -f "$folder/$title/review.html" ]; then
                    echo -e "${yellow}Review already exists!${nc}"
                else
                    echo -e "${yellow}Download review: ${nc}"
                    d_wget "$review_url" "$folder/$title/review.html"
                fi

                if [ -f "$folder/$title/${pdf_name:0:-4}.zip" ]; then
                    if [ -f "$folder/$title/$folder/$title/${pdf_name:0:-4}-merge.pdf" ]; then
                        echo -e "${yellow}Merge file already exists!${nc}"
                    else
                        echo -e "${yellow}Unzip and merge:${nc} ${pdf_name:0:-4}-merge.pdf"
                        create d "$folder/$title/supp/"
                        unzip -q "$folder/$title/${pdf_name:0:-4}.zip" -d "$folder/$title/supp/"
                        merge_command="gs -dBATCH -dNOPAUSE -q -sDEVICE=pdfwrite -sOutputFile='$folder/$title/${pdf_name:0:-4}-merge.pdf' '$folder/$title/$pdf_name'"
                        for line in $(find "$folder/$title/supp/" -maxdepth 1 -regextype posix-extended -iregex '.*\.(pdf|PDF)' | tr ' ' '\?'); do
                            merge_command="$merge_command '$line'"
                        done
                        merge_command=$(echo "$merge_command" | tr '\?' ' ')
                        eval "$merge_command"
                        delete d "$folder/$title/supp/"
                    fi
                fi

                delete f "$html_cache/paper.html"
                ;;
            esac
        fi
        ((i++))
    done
else
    echo -e "${red}Warning: there is nothing to do!${nc}"
fi
